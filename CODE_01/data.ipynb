{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cf4362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "import geotiler\n",
    "from shapely import wkt\n",
    "from shapely.ops import cascaded_union\n",
    "import structlog\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import crop as torchvision_crop\n",
    "\n",
    "LOGGER = structlog.get_logger()\n",
    "\n",
    "INPUT_HEIGHT, INPUT_WIDTH = 512, 512\n",
    "RAW_HEIGHT, RAW_WIDTH = 1024, 1024\n",
    "\n",
    "DAMAGE_COLOUR_MAPPING = {\n",
    "    \"no-damage\": (30, 30, 30),\n",
    "    \"minor-damage\": (75, 75, 75),\n",
    "    \"major-damage\": (150, 150, 150),\n",
    "    \"destroyed\": (225, 225, 225),\n",
    "    \"un-classified\": (255, 255, 255)\n",
    "}\n",
    "BACKGROUND_COLOUR_MAPPING = {\n",
    "    'mexico-earthquake': (0, 0, 0, 50),\n",
    "    'portugal-wildfire': (40, 0, 0, 50),\n",
    "    'woolsey-fire': (80, 0, 0, 50),\n",
    "    'pinery-bushfire': (120, 0, 0, 50),\n",
    "    'santa-rosa-wildfire': (160, 0, 0, 50),\n",
    "    'socal-fire': (200, 0, 0, 50),\n",
    "    'hurricane-florence': (240, 0, 0, 50),\n",
    "    'midwest-flooding': (255, 25, 0, 50),\n",
    "    'hurricane-harvey': (255, 65, 0, 50),\n",
    "    'nepal-flooding': (255, 105, 0, 50),\n",
    "    'sunda-tsunami': (255, 145, 0, 50),\n",
    "    'palu-tsunami': (255, 185, 0, 50),\n",
    "    'guatemala-volcano': (255, 225, 0, 50),\n",
    "    'lower-puna-volcano': (255, 255, 10, 50),\n",
    "    'hurricane-michael': (255, 255, 50, 50),\n",
    "    'joplin-tornado': (255, 255, 90, 50),\n",
    "    'moore-tornado': (255, 255, 130, 50),\n",
    "    'tuscaloosa-tornado': (255, 255, 170, 50),\n",
    "    'hurricane-matthew': (255, 255, 210, 50)\n",
    "}\n",
    "\n",
    "TRANSFORMS = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "\n",
    "def get_label_path(p: Path) -> Path:\n",
    "    return Path(str(p).replace(\"images\", \"labels\").replace(\".png\", \".json\"))\n",
    "\n",
    "\n",
    "def get_label_image_path(p: Path) -> Path:\n",
    "    return Path(str(p).replace(\"images\", \"labels\"))\n",
    "\n",
    "\n",
    "def has_buildings(image_path: Path) -> bool:\n",
    "    with get_label_path(image_path).open() as f:\n",
    "        label_data = json.load(f)\n",
    "\n",
    "    return len(label_data[\"features\"][\"xy\"]) > 0\n",
    "\n",
    "\n",
    "def estimate_image_bounds(\n",
    "        image_path: Path,\n",
    "        width: int,\n",
    "        height: int\n",
    ") -> Optional[Tuple[float, float, float, float]]:\n",
    "    try:\n",
    "        with get_label_path(image_path).open() as f:\n",
    "            label_data = json.load(f)\n",
    "\n",
    "        # Load all the geometries\n",
    "        xy_geoms = [wkt.loads(feat[\"wkt\"]) for feat in label_data[\"features\"][\"xy\"]]\n",
    "        lng_lat_geoms = [wkt.loads(feat[\"wkt\"]) for feat in label_data[\"features\"][\"lng_lat\"]]\n",
    "\n",
    "        # Building positions\n",
    "        min_x, min_y, max_x, max_y = cascaded_union(xy_geoms).bounds\n",
    "        min_lon, min_lat, max_lon, max_lat = cascaded_union(lng_lat_geoms).bounds\n",
    "\n",
    "        # Building size in pixels\n",
    "        x_size = max_x - min_x\n",
    "        y_size = max_y - min_y\n",
    "\n",
    "        # Building size in degrees\n",
    "        lon_size = abs(min_lon) - abs(max_lon)\n",
    "        lat_size = abs(max_lat) - abs(min_lat)\n",
    "\n",
    "        # How much of a long / lat is needed per pixel\n",
    "        lons_per_pixel = (lon_size / x_size)\n",
    "        lats_per_pixel = (lat_size / y_size)\n",
    "\n",
    "        # Calculation for the bounding box of the image\n",
    "        bounds_min_lon = min_lon - abs(min_x * lons_per_pixel)\n",
    "        bounds_min_lat = min_lat + abs(min_y * lats_per_pixel)\n",
    "        bounds_max_lon = max_lon + abs((width - max_x) * lons_per_pixel)\n",
    "        bounds_max_lat = max_lat - abs((height - max_y) * lats_per_pixel)\n",
    "\n",
    "        return bounds_min_lon, bounds_min_lat, bounds_max_lon, bounds_max_lat\n",
    "    except ValueError:\n",
    "        LOGGER.warn(\"Unable to estimate bounds for.\", image_path=image_path)\n",
    "        return None\n",
    "\n",
    "\n",
    "FUDGE_FACTOR = 1.2\n",
    "\n",
    "def create_label_image(\n",
    "        label_data: dict,\n",
    "        width: int, height: int,\n",
    "        bounds: Tuple[float, float, float, float]\n",
    ") -> Image:\n",
    "    # Create a label image based on the OSM data for the bounds.\n",
    "    fudged_width = int(round(width * FUDGE_FACTOR))\n",
    "    fudged_height = int(round(height * FUDGE_FACTOR))\n",
    "    map_aoi = geotiler.Map(extent=bounds, size=(fudged_width, fudged_height))\n",
    "    label_image = geotiler.render_map(map_aoi).convert('RGB')\n",
    "\n",
    "    # Hack the relevant part of the tile out.\n",
    "    left = (map_aoi.extent[0] - bounds[0]) / (map_aoi.extent[0] - map_aoi.extent[2]) * fudged_width\n",
    "    right = (bounds[2] - map_aoi.extent[2]) / (map_aoi.extent[0] - map_aoi.extent[2]) * fudged_width\n",
    "\n",
    "    top = (map_aoi.extent[1] - bounds[1]) / (map_aoi.extent[1] - map_aoi.extent[3]) * fudged_height\n",
    "    bottom = (bounds[3] - map_aoi.extent[3]) / (map_aoi.extent[1] - map_aoi.extent[3]) * fudged_height\n",
    "\n",
    "    label_image = label_image.crop(box=(left, top, fudged_width - right, fudged_height - bottom))\n",
    "    label_image = label_image.resize((width, height))\n",
    "\n",
    "    # Tint the label image with a colour based on the disaster code.\n",
    "    background_image = Image.new(\"RGBA\", (width, height))\n",
    "    ImageDraw.Draw(background_image, \"RGBA\").polygon(\n",
    "        [\n",
    "            (0, 0),\n",
    "            (height, 0),\n",
    "            (height, width),\n",
    "            (0, width)\n",
    "        ],\n",
    "        BACKGROUND_COLOUR_MAPPING[label_data[\"metadata\"][\"disaster\"]]\n",
    "    )\n",
    "    label_image.paste(background_image, (0, 0), background_image)\n",
    "\n",
    "    # Add each building to the image (with a colour corresponding to the\n",
    "    # level of the damage.\n",
    "    for building in label_data[\"features\"][\"xy\"]:\n",
    "        x, y = wkt.loads(building[\"wkt\"]).exterior.coords.xy\n",
    "        p = list(zip(x, y))\n",
    "        try:\n",
    "            colour = DAMAGE_COLOUR_MAPPING[building[\"properties\"][\"subtype\"]]\n",
    "        except KeyError:\n",
    "            # In the case that the building has no 'subtype' property the\n",
    "            # building is not damaged\n",
    "            colour = DAMAGE_COLOUR_MAPPING[\"no-damage\"]\n",
    "\n",
    "        ImageDraw.Draw(label_image).polygon(p, colour)\n",
    "\n",
    "    return label_image\n",
    "\n",
    "\n",
    "def cache_label_image(image_path: Path, bounds: Tuple[float, float, float, float]):\n",
    "    with get_label_path(image_path).open() as f:\n",
    "        label_data = json.load(f)\n",
    "\n",
    "    label_image = create_label_image(label_data, RAW_WIDTH, RAW_HEIGHT, bounds)\n",
    "    label_image.save(get_label_image_path(image_path))\n",
    "\n",
    "\n",
    "class XView2Dataset(Dataset):\n",
    "    def __init__(self, directory: Path, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._directory = directory\n",
    "\n",
    "        LOGGER.info(\"Initialising samples.\")\n",
    "        self._samples = [\n",
    "            {\n",
    "                \"image_path\": path,\n",
    "                \"label_path\": get_label_path(path),\n",
    "                \"label_image_path\": get_label_image_path(path),\n",
    "                \"bounds\": bounds\n",
    "            }\n",
    "            for path in list((directory / Path(\"images\")).glob(\"*.png\"))\n",
    "            for bounds in [estimate_image_bounds(path, RAW_WIDTH, RAW_HEIGHT)]\n",
    "            if get_label_image_path(path).is_file() or (has_buildings(path) and bounds is not None)\n",
    "        ]\n",
    "        LOGGER.info(\"Initialising samples completed.\", sample_count=len(self._samples))\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        sample = self._samples[item]\n",
    "\n",
    "        image_path = sample[\"image_path\"]\n",
    "        label_image_path = sample[\"label_image_path\"]\n",
    "\n",
    "        if not label_image_path.is_file():\n",
    "            LOGGER.info(\"Caching image.\", image_path=image_path)\n",
    "            cache_label_image(image_path, sample[\"bounds\"])\n",
    "            LOGGER.info(\"Cached image successfully.\", image_path=image_path)\n",
    "\n",
    "        y = Image.open(image_path)\n",
    "        x = Image.open(label_image_path)\n",
    "\n",
    "        # Apply the same random crop to both the images\n",
    "        i, j, h, w = transforms.RandomCrop.get_params(\n",
    "            x, output_size=(INPUT_HEIGHT, INPUT_WIDTH)\n",
    "        )\n",
    "        x = torchvision_crop(x, i, j, h, w)\n",
    "        y = torchvision_crop(y, i, j, h, w)\n",
    "\n",
    "        return TRANSFORMS(x), TRANSFORMS(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._samples)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
